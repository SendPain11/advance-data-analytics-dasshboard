# ğŸ“Š Advanced Data Analytics & Machine Learning Dashboard

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Status](https://img.shields.io/badge/Status-Production-success.svg)

A comprehensive, production-ready data analytics dashboard built with Python, showcasing advanced data science, machine learning, and statistical analysis capabilities. Perfect for data-driven business intelligence and predictive analytics.

## ğŸ¯ Project Overview

This dashboard is a full-featured analytics platform that demonstrates enterprise-level data science workflows, from exploratory data analysis to machine learning model deployment. It's designed to showcase professional Python programming skills and real-world data science applications.

### âœ¨ Key Features

- **ğŸ“ˆ Exploratory Data Analysis (EDA)**
  - Interactive data visualization with Plotly
  - Statistical distribution analysis
  - Correlation matrix and heatmaps
  - Automated outlier detection using IQR method
  - Descriptive statistics with skewness & kurtosis

- **ğŸ¤– Machine Learning Models**
  - Multiple algorithm comparison (Linear Regression, Random Forest, Gradient Boosting)
  - Real-time model training OR pre-trained model loading
  - Automated model evaluation with comprehensive metrics
  - Feature importance analysis
  - Interactive predictions vs actual visualization

- **ğŸ¨ Customer Segmentation**
  - K-Means clustering implementation
  - Elbow method for optimal cluster selection
  - 3D interactive cluster visualization
  - Cluster characteristics profiling

- **ğŸ“Š Statistical Hypothesis Testing**
  - Independent T-Tests for group comparison
  - ANOVA for multi-group analysis
  - Pearson correlation testing
  - Automated p-value interpretation

- **â° Time Series Analysis**
  - Trend decomposition
  - Seasonality detection
  - Moving average forecasting
  - Interactive time range selection

## ğŸš€ Quick Start

### Prerequisites

```bash
Python 3.8 or higher
pip (Python package manager)
```

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/SendPain11/advanced-analytics-dashboard.git
cd advanced-analytics-dashboard
```

2. **Create virtual environment (recommended)**
```bash
python -m venv venv

# On Windows
venv\Scripts\activate

# On macOS/Linux
source venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

## ğŸ® Running the Application

### Option 1: Quick Demo (Recommended for Portfolio)

**Real-time model training - No setup required!**

```bash
streamlit run app.py
```

The dashboard will:
- âœ… Automatically generate sample data
- âœ… Train models in real-time (< 5 seconds)
- âœ… Display interactive visualizations
- âœ… Show predictions immediately

**Perfect for:** Demos, interviews, portfolio presentations

---

### Option 2: Production Mode (With Pre-trained Models)

**For production-style deployment with saved models**

#### Step 1: Train and Save Models

```bash
python train_model.py
```

This will:
- Train all ML models with your data
- Save models to `models/` directory
- Create metadata for model versioning
- Generate performance reports

Output:
```
ğŸš€ Starting model training...
ğŸ“Š Training Linear_Regression...
   âœ… RÂ² Score: 0.8542
ğŸ“Š Training Random_Forest...
   âœ… RÂ² Score: 0.9123
ğŸ“Š Training Gradient_Boosting...
   âœ… RÂ² Score: 0.9087
ğŸ† Best Model: Random_Forest
ğŸ’¾ Saving models to models/...
   âœ… Saved models/linear_regression_model.pkl
   âœ… Saved models/random_forest_model.pkl
   âœ… Saved models/gradient_boosting_model.pkl
âœ¨ All models saved successfully!
```

#### Step 2: Run Dashboard with Pre-trained Models

```bash
streamlit run app.py
```

Then in the sidebar:
- â˜‘ï¸ Check "Use Pre-trained Models"
- Dashboard will load models from disk
- Faster predictions (no training needed)

**Perfect for:** Production deployment, scheduled retraining, large datasets

---

## ğŸ“¦ Dependencies

**requirements.txt:**
```
streamlit>=1.28.0
pandas>=2.0.0
numpy>=1.24.0
plotly>=5.17.0
scikit-learn>=1.3.0
scipy>=1.11.0
seaborn>=0.12.0
matplotlib>=3.7.0
```

Install all at once:
```bash
pip install -r requirements.txt
```

## ğŸ—ï¸ Project Structure

```
advanced-analytics-dashboard/
â”‚
â”œâ”€â”€ app.py                      # Main Streamlit dashboard (REQUIRED)
â”œâ”€â”€ train_model.py              # Optional: Separate training script
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # This file
â”‚
â”œâ”€â”€ models/                     # Created by train_model.py
â”‚   â”œâ”€â”€ linear_regression_model.pkl
â”‚   â”œâ”€â”€ random_forest_model.pkl
â”‚   â”œâ”€â”€ gradient_boosting_model.pkl
â”‚   â”œâ”€â”€ scaler.pkl
â”‚   â””â”€â”€ metadata.json           # Model versioning info
â”‚
â”œâ”€â”€ data/                       # Optional: Your datasets
â”‚   â””â”€â”€ custom_data.csv
â”‚
â””â”€â”€ media/                # Optional: For README
    â”œâ”€â”€ screnshoot.png
    â””â”€â”€ video.mkv
```

## ğŸ’» Usage Guide

### 1. Dashboard Interface

When you run `streamlit run app.py`, you'll see:

**Sidebar:**
- ğŸ”„ **Use Pre-trained Models**: Toggle to load saved models
- ğŸ“Š **Data Source**: Choose sample data or upload CSV
- âš™ï¸ **Analysis Types**: Select which analyses to run

**Main Panel:**
- ğŸ“‹ Data Overview with key metrics
- ğŸ“Š Interactive visualizations
- ğŸ¤– ML model comparisons
- ğŸ“ˆ Statistical test results

### 2. Sample Workflows

#### Workflow A: Quick Data Analysis
```
1. Run: streamlit run app.py
2. Select: "Generate Sample Sales Data"
3. Choose: "Exploratory Data Analysis"
4. Explore: Distributions, correlations, outliers
```

#### Workflow B: Build Predictive Models
```
1. Run: streamlit run app.py
2. Select: "Generate Sample Sales Data"
3. Choose: "Predictive Modeling"
4. Adjust: Test set size slider
5. Compare: 3 ML algorithms automatically
6. Review: RÂ², RMSE, MAE metrics
```

#### Workflow C: Customer Segmentation
```
1. Run: streamlit run app.py
2. Select: "Generate Sample Sales Data"
3. Choose: "Clustering Analysis"
4. Adjust: Number of clusters
5. Visualize: 3D cluster plot
6. Analyze: Cluster characteristics
```

### 3. Upload Your Own Data

```
1. In sidebar, select: "Upload Your Own CSV"
2. Click: Upload CSV file
3. Dashboard will automatically:
   - Detect numeric columns
   - Run selected analyses
   - Generate visualizations
```

## ğŸ“ Skills Demonstrated

This project showcases proficiency in:

- **Python Programming**: Advanced techniques, OOP, functional programming
- **Data Science**: Statistical analysis, hypothesis testing, data visualization
- **Machine Learning**: Supervised learning, clustering, model evaluation, hyperparameter tuning
- **Data Engineering**: ETL pipelines, feature engineering, data preprocessing
- **Web Development**: Streamlit framework, interactive dashboards, UX design
- **Software Engineering**: Code organization, documentation, version control, testing
- **Production Deployment**: Model persistence, caching, performance optimization

## ğŸ”§ Technical Deep Dive

### Machine Learning Pipeline

```python
# Automatic workflow in app.py:
1. Data Ingestion â†’ Generate or upload
2. Data Validation â†’ Type checking, null handling
3. Train-Test Split â†’ Configurable ratio
4. Feature Scaling â†’ StandardScaler normalization
5. Model Training â†’ 3 algorithms in parallel
6. Evaluation â†’ Multiple metrics calculation
7. Visualization â†’ Interactive Plotly charts
```

### Model Training Options

**Option A: Real-time Training (app.py)**
- Trains models on-demand when user selects "Predictive Modeling"
- Uses `@st.cache_data` for performance
- Best for: Demos, small datasets, rapid iteration

**Option B: Pre-trained Models (train_model.py)**
- Trains models once, saves to disk
- Loads pre-trained models in dashboard
- Supports hyperparameter tuning
- Best for: Production, large datasets, scheduled retraining

### Performance Optimization

- **Caching**: `@st.cache_data` and `@st.cache_resource` for expensive operations
- **Lazy Loading**: Data loaded only when needed
- **Vectorization**: NumPy/Pandas for fast computations
- **Efficient Algorithms**: Scikit-learn's optimized implementations

## ğŸ“Š Model Information

### Algorithms Implemented

1. **Linear Regression**
   - Fast baseline model
   - Interpretable coefficients
   - Assumes linear relationships

2. **Random Forest**
   - Ensemble method with 100 trees
   - Handles non-linear relationships
   - Provides feature importance
   - Usually best performer

3. **Gradient Boosting**
   - Sequential ensemble method
   - Strong predictive power
   - Captures complex patterns

### Evaluation Metrics

- **RÂ² Score**: Variance explained by model (0-1, higher is better)
- **RMSE**: Root Mean Squared Error (lower is better)
- **MAE**: Mean Absolute Error (lower is better)

## ğŸ”’ Data Privacy & Security

- âœ… No data stored permanently
- âœ… All processing in-memory
- âœ… Sample data uses seeded randomization
- âœ… Uploaded data not logged
- âœ… Models saved only if explicitly trained via `train_model.py`

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create feature branch: `git checkout -b feature/AmazingFeature`
3. Commit changes: `git commit -m 'Add AmazingFeature'`
4. Push to branch: `git push origin feature/AmazingFeature`
5. Open Pull Request

## ğŸ“ Future Enhancements

**Planned Features:**
- [ ] Deep Learning models (LSTM, Neural Networks)
- [ ] Real-time data streaming (Apache Kafka)
- [ ] REST API for predictions (FastAPI)
- [ ] Advanced time series (ARIMA, Prophet, Transformer models)
- [ ] NLP module for text analytics
- [ ] Automated report generation (PDF/Excel)
- [ ] User authentication (OAuth)
- [ ] Database integration (PostgreSQL, MongoDB)
- [ ] Docker containerization
- [ ] Cloud deployment (AWS, GCP, Azure)
- [ ] A/B testing framework
- [ ] Model monitoring & drift detection

## ğŸ› Troubleshooting

### Common Issues

**Issue: Port already in use**
```bash
# Solution: Use different port
streamlit run app.py --server.port 8502
```

**Issue: Models not loading**
```bash
# Solution: Ensure models/ directory exists and run:
python train_model.py
```

**Issue: Import errors**
```bash
# Solution: Reinstall dependencies
pip install -r requirements.txt --upgrade
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¤ Author

**Sendy Prismana Nurferian**
- GitHub: [@yourusername](https://github.com/SendPain11)
- LinkedIn: [Your LinkedIn](https://www.linkedin.com/in/sendy-prismana-nurferian-95a27b213/)
- Email: sendyprisma02@gmail.com
- Documentation Project: [streamlit web](https://advance-analytics-data-dashboard.streamlit.app/)

## ğŸ™ Acknowledgments

- [Streamlit](https://streamlit.io/) - Amazing framework for data apps
- [Scikit-learn](https://scikit-learn.org/) - Robust ML library
- [Plotly](https://plotly.com/) - Beautiful interactive visualizations
- Open source community for inspiration

## ğŸ“ Support

Need help?
- ğŸ“§ Email: sendyprism02@gmail.com
- ğŸ’¬ Open an [issue](https://github.com/SendPain11/advanced-analytics-dashboard/issues)
- ğŸ”— Connect on [LinkedIn](https://www.linkedin.com/in/sendy-prismana-nurferian-95a27b213/)

---

## ğŸ¯ Quick Command Reference

```bash
# Install dependencies
pip install -r requirements.txt

# Quick demo (recommended)
streamlit run app.py

# Production mode
python train_model.py          # Train & save models
streamlit run app.py           # Run dashboard
# â†’ Check "Use Pre-trained Models" in sidebar

# Run on different port
streamlit run app.py --server.port 8502

# Run with auto-reload
streamlit run app.py --server.runOnSave true
```

---

**â­ If you find this project useful, please give it a star on GitHub!**

**Made with â¤ï¸ and Python** ğŸ

**See You Next Time all!**
---
